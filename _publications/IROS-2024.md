---
title: "Collaboration Strategies for Two Heterogeneous Pursuers in A Pursuit-Evasion Game Using Deep Reinforcement Learning."
collection: publications
category: conferences
permalink: /publication/IROS-2024
excerpt: 'An interest pursuit-evasion scenarior and a new collaboration strategies.'
date: 2024-06-30
venue: 'IEEE/RSJ International Conference on Intelligent Robots and Systems'
# slidesurl: 'http://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10802839'
bibtexurl: 'https://scholar.googleusercontent.com/scholar.bib?q=info:TD6wUywDJbgJ:scholar.google.com/&output=citation&scisdr=CgItHyKdEPCEqddp-8o:AAZF9b8AAAAAaHhv48rR4OexPDWstg5oV875g64&scisig=AAZF9b8AAAAAaHhv45Pq1XHdeyIlooAPaGdEVnM&scisf=4&ct=citation&cd=-1&hl=zh-CN'
citation: 'Z. Zhong, Z. Dong, X. Duan, J. He. Collaboration Strategies for Two Heterogeneous Pursuers in A Pursuit-Evasion Game Using Deep Reinforcement Learning. IEEE/RSJ International Conference on Intelligent Robots and Systems, Abu Dhabi, UAE, October 2024.'
---

**Abstract:**

We investigate a pursuit-evasion game taking place in an unbounded three-dimensional space, where a flexible pursuer with hybrid dynamics collaborates with a fast pursuer and aims to capture a flexible evader within a finite time. The key feature of this problem lies in the hybrid dynamics of the flexible pursuer, which can change its dynamics once during the game and switch to a fast pursuer with increased speed but lower maneuverability. To address this challenge, we devise a hybrid strategy based on the soft actor-critic framework, tailored specifically for the flexible pursuer, which encompasses both maneuvering and switch tactics. We introduce a switch factor to the input of the actor network and incorporate switch actions to further expand the action space. These additions enable the flexible pursuer to execute maneuvering actions and determine a moment to switch to a fast pursuer. The reward function is designed to account for related angle, altitude, speed, and sparse reward. Through extensive ablation experiments conducted in a simulated environment, we demonstrate the efficacy of our algorithm in facilitating the learning of hybrid strategies for the flexible pursuer, resulting in significantly improved capture rates compared to alternative methods.